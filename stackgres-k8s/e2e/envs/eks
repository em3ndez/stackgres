#!/bin/sh

K8S_EKS_NAME="${K8S_EKS_NAME:-stackgres-e2e}"
K8S_EKS_REGION="${K8S_EKS_REGION:-us-west-2}"
K8S_EKS_NODE_TYPE="${K8S_EKS_NODE_TYPE:-m5.large}"
K8S_EKS_NODES="${K8S_EKS_NODES:-1}"
K8S_EKS_DISK_SIZE="${K8S_EKS_DISK_SIZE:-20}"
K8S_EKS_USE_SPOT="${K8S_EKS_USE_SPOT:-true}"
K8S_EKS_OPTS="$K8S_EKS_OPTS"
EKS_EXPANDABLE_STORAGE_CLASSNAME="${EXPANDABLE_STORAGE_CLASSNAME:-expandable-sc}"

export K8S_EKS_NAME K8S_VERSION K8S_EKS_REGION K8S_EKS_NODE_LOCATIONS K8S_EKS_NODE_TYPE K8S_EKS_OPTS

get_k8s_env_version() {
  echo "eksctl version $(eksctl version)"
  echo
}

reuse_k8s() {
  if ! eksctl get cluster --name "$K8S_EKS_NAME" --region "$K8S_EKS_REGION" 2>&1 \
    | grep "^$K8S_EKS_NAME" | grep -q "ACTIVE"
  then
    echo "Can not reuse eks environment $K8S_EKS_NAME"
    reset_k8s
    return
  fi

  echo "Reusing eks environment $K8S_EKS_NAME"

  aws eks update-kubeconfig --name "$K8S_EKS_NAME" --region "$K8S_EKS_REGION"

  create_and_use_cluster_admin_fast
}

create_and_use_cluster_admin_fast() {
  kubectl create sa cluster-admin-fast 2>/dev/null || true
  kubectl create clusterrolebinding cluster-admin-fast --clusterrole=cluster-admin --serviceaccount=default:cluster-admin-fast 2>/dev/null || true
  SECRET="$(kubectl get sa cluster-admin-fast -o json | jq -r '.secrets[].name')"
  kubectl get secret "$SECRET" -o json | jq -r '.data["ca.crt"]' | base64 -d > "$TARGET_PATH/eks-ca.crt"
  USER_TOKEN=$(kubectl get secret "$SECRET" -o json | jq -r '.data["token"]' | base64 -d)
  CURRENT_CONTEXT="$(kubectl config current-context)"
  CURRENT_CONTEXT_CLUSTER="$(kubectl config get-contexts "$CURRENT_CONTEXT" | tail -n +2 | tr -s ' \t' ' ' | cut -d ' ' -f 3 | tail -n 1)"
  CURRENT_CONTEXT_ENDPOINT="$(kubectl config view -o jsonpath="{.clusters[?(@.name == \"$CURRENT_CONTEXT_CLUSTER\")].cluster.server}")"
  kubectl config delete-cluster "$CURRENT_CONTEXT_CLUSTER-fast" 2>/dev/null || true
  kubectl config set-cluster "$CURRENT_CONTEXT_CLUSTER-fast" \
    --embed-certs=true \
    --server="$CURRENT_CONTEXT_ENDPOINT" \
    --certificate-authority="$TARGET_PATH/eks-ca.crt"
  kubectl config delete-user "$CURRENT_CONTEXT-fast" 2>/dev/null || true
  kubectl config set-credentials "$CURRENT_CONTEXT-fast" \
    --token="$USER_TOKEN"
  kubectl config set-context "$CURRENT_CONTEXT-fast" \
    --cluster="$CURRENT_CONTEXT_CLUSTER-fast" \
    --user="$CURRENT_CONTEXT-fast" \
    --namespace=default
  kubectl config use-context "$CURRENT_CONTEXT-fast"
}

reset_k8s() {
  echo "Setting up eks environment $K8S_EKS_NAME..."

  delete_k8s

  eksctl create cluster --name "$K8S_EKS_NAME" \
    $([ "$K8S_EKS_USE_SPOT" != true ] || printf %s --spot) \
    --region "$K8S_EKS_REGION" \
    --node-type "$K8S_EKS_NODE_TYPE" \
    --node-volume-size "$K8S_EKS_DISK_SIZE" \
    --nodes "$K8S_EKS_NODES" \
    --version "$(printf %s "$K8S_VERSION" | cut -d . -f 1-2)"
  
  echo "...done"
}

delete_k8s() {
  echo "Checking if eks environment $K8S_EKS_NAME exists"

  if eksctl get cluster --name "$K8S_EKS_NAME" --region "$K8S_EKS_REGION" 2>&1 \
    | grep "^$K8S_EKS_NAME" | grep -q "ACTIVE"
  then
    echo "EKS environment $K8S_EKS_NAME detected, deleteing..."
    eksctl delete cluster --wait --name "$K8S_EKS_NAME" --region "$K8S_EKS_REGION" || true
  else
    echo "EKS environment $K8S_EKS_NAME not detected"
  fi
  
  echo "Cleaning volumes related to the $K8S_EKS_NAME cluster"
  aws ec2 describe-volumes --region "$K8S_EKS_REGION" --filters "Name=tag-key,Values=kubernetes.io/cluster/$K8S_EKS_NAME" \
    | jq -r '.Volumes[].VolumeId' | xargs -r -n 1 -I % sh -c "aws ec2 detach-volume --force --region $K8S_EKS_REGION --volume-id % || true"
  
  aws ec2 describe-volumes --region "$K8S_EKS_REGION" --filters "Name=tag-key,Values=kubernetes.io/cluster/$K8S_EKS_NAME" \
    | jq -r '.Volumes[].VolumeId' | xargs -r -n 1 -I % sh -c "aws ec2 delete-volume --region $K8S_EKS_REGION --volume-id % || true" 

  echo "...done"
}

load_image_k8s() {
  echo "Cannot load images directly to k8s in a eks environment"
  exit 1
}

get_k8s_versions() {
  cat << EOF
1.16.8
1.15.11
1.14.9
1.13.12
EOF
}

excluded_validatingwebhookconfigurations() {
  echo "vpc-resource-validating-webhook"
}

excluded_mutatingwebhookconfigurations() {
  echo "pod-identity-webhook"
  echo "vpc-resource-mutating-webhook"
}

excluded_customresourcedefinitions() {
  echo ".*\.amazonaws\.com"
  echo ".*\.k8s\.aws"
}

excluded_podsecuritypolicies() {
  echo "eks\.privileged"
}

excluded_clusterroles() {
  echo "aws-node"
  echo "eks:.*"
  echo "vpc-resource-controller-role"
}

excluded_clusterrolebindings() {
  echo "aws-node"
  echo "eks:.*"
  echo "vpc-resource-controller-rolebinding"
}


get_eks_storage_class_name() {
  kubectl get storageclasses.storage.k8s.io \
      -o custom-columns=NAME:.metadata.name,IS_DEFAULT:".metadata.annotations.storageclass\.kubernetes\.io/is-default-class" \
      | awk '{ if ($2 == "true") { print } }' \
      | awk '{print $1}' \
      | head -n +1
}

create_expandable_storage_class_k8s() {
  local DEFAULT_STORAGE_CLASSNAME
  DEFAULT_STORAGE_CLASSNAME="$(get_eks_storage_class_name)"
  generate_expandable_storage_class_from \
    "$DEFAULT_STORAGE_CLASSNAME" \
    "$EKS_EXPANDABLE_STORAGE_CLASSNAME" \
    | kubectl apply -f - > /dev/null
  printf '%s' "$EKS_EXPANDABLE_STORAGE_CLASSNAME"
}
